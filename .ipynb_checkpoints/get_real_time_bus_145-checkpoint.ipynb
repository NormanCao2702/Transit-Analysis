{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3699fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3e73a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your API key for authorization\n",
    "api_key = 'bf26424bdabada8b6cb6769478a36213bd864f1773e7a3ac5ecfc15ef83830ce'\n",
    "# Header parameters\n",
    "headers = {\n",
    "    'apiKey': api_key,  # Authorization with API key\n",
    "    'Accept-Language': 'en'  # Optional: Language preference\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b8342a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Production way bay 1 global stop id\n",
    "production_way_bay_1_stop = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "367b5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connecting_endpoint():\n",
    "    # API endpoint for nearby stops\n",
    "    nearby_stops_url= \"https://external.transitapp.com/v3/public/nearby_stops\"\n",
    "    # Query parameters\n",
    "    params_nearby_stops = {\n",
    "        'lat': 49.25348197787918,  # Latitude\n",
    "        'lon': -122.91818244659417,  # Longitude\n",
    "        'max_distance': 150,  # Maximum radius of search from the request location in meters\n",
    "        'stop_filter': 'Routable',  # Type of stops to return\n",
    "        # Optional: you can add 'pickup_dropoff_filter' parameter here if needed\n",
    "    }\n",
    "    # Make the GET request\n",
    "    response_nearby = requests.get(nearby_stops_url, params=params_nearby_stops, headers=headers)\n",
    "    return response_nearby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46b7277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_global_id(response_nearby, desired_stop_name):\n",
    "    # Check if the request was successful\n",
    "    if response_nearby.status_code == 200:\n",
    "        data = response_nearby.json()\n",
    "\n",
    "        stops = data['stops']\n",
    "\n",
    "        # Loop through each stop in the response and print its global_stop_id\n",
    "#         for stop in stops:\n",
    "#             print(f\"Stop Name: {stop['stop_name']}, Global Stop ID: {stop['global_stop_id']}\")\n",
    "\n",
    "        # Desired stop name\n",
    "#         stop_name = \"Production Way Station (Bay 1)\"\n",
    "        for stop in stops:\n",
    "            if stop[\"stop_name\"] == desired_stop_name:\n",
    "#                 production_way_bay_1_stop = stop[\"global_stop_id\"]\n",
    "                return stop[\"global_stop_id\"]\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce7b5f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time():\n",
    "    return int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55527456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stop_departures(global_stop_id, current_time):\n",
    "    stop_departures_url = \"https://external.transitapp.com/v3/public/stop_departures\"\n",
    "\n",
    "    # Query parameters\n",
    "    params_stop_departures = {\n",
    "        'global_stop_id': global_stop_id,\n",
    "        'time': current_time,  # You can adjust this according to your needs\n",
    "        'should_update_realtime': True,\n",
    "        'remove_cancelled': False # Set to True if you want to remove cancelled schedule items\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response_stop_depart = requests.get(stop_departures_url, params=params_stop_departures, headers=headers)\n",
    "    return response_stop_depart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19d329b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stop_departures(response):\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        departures = []\n",
    "        # Extracting data\n",
    "        for route_departure in data['route_departures']:\n",
    "            for itinerary in route_departure['itineraries']:\n",
    "                for schedule_item in itinerary['schedule_items']:\n",
    "                    departure_info = {\n",
    "                        'RT_Trip_ID': schedule_item['rt_trip_id'],\n",
    "                        'Departure_Time': schedule_item['departure_time'],\n",
    "                        'Scheduled_Departure_Time': schedule_item['scheduled_departure_time'],\n",
    "                        'Is_Cancelled': schedule_item['is_cancelled']\n",
    "                    }\n",
    "                    departures.append(departure_info)\n",
    "                    print(f\"RT Trip ID: {schedule_item['rt_trip_id']}, Departure Time: {schedule_item['departure_time']}, Scheduled Departure Time: {schedule_item['scheduled_departure_time']}, Is cancelled: {schedule_item['is_cancelled']}\")\n",
    "        return departures\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ce15910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_or_append_departures(departures_df, csv_file='departures_info.csv'):\n",
    "    try:\n",
    "        existing_df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        existing_df = pd.DataFrame(columns=departures_df.columns)\n",
    "    \n",
    "    for index, new_row in departures_df.iterrows():\n",
    "        trip_id = new_row['RT_Trip_ID']\n",
    "        if trip_id in existing_df['RT_Trip_ID'].values:\n",
    "            existing_df.loc[existing_df['RT_Trip_ID'] == trip_id, :] = new_row\n",
    "        else:\n",
    "            # Use pd.concat to append the new row\n",
    "            existing_df = pd.concat([existing_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    existing_df.to_csv(csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "36019f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Desired stop name\n",
    "    desired_stop_name = \"Production Way Station (Bay 1)\"\n",
    "\n",
    "#     response_nearby = connecting_endpoint()\n",
    "#     production_way_bay_1_stop = get_stop_global_id(response_nearby, desired_stop_name)\n",
    "    \n",
    "#     if production_way_bay_1_stop:\n",
    "#         print(f\"Global Stop ID for '{desired_stop_name}': {production_way_bay_1_stop}\")\n",
    "#     else:\n",
    "#         print(f\"Stop '{desired_stop_name}' not found.\")\n",
    "    \n",
    "    production_way_bay_1_stop = \"TSL:74401\"\n",
    "    \n",
    "    current_time = get_current_time()\n",
    "    response = fetch_stop_departures(production_way_bay_1_stop, current_time)\n",
    "    \n",
    "    departures = process_stop_departures(response)\n",
    "    departures_df = pd.DataFrame(departures)\n",
    "    \n",
    "    # Define the timezone for Vancouver\n",
    "    vancouver_tz = pytz.timezone('America/Vancouver')\n",
    "    # Convert UNIX time to datetime objects in UTC, then convert to Vancouver timezone\n",
    "    departures_df['Departure_Time'] = pd.to_datetime(departures_df['Departure_Time'], unit='s').dt.tz_localize('UTC').dt.tz_convert(vancouver_tz)\n",
    "    departures_df['Scheduled_Departure_Time'] = pd.to_datetime(departures_df['Scheduled_Departure_Time'], unit='s').dt.tz_localize('UTC').dt.tz_convert(vancouver_tz)\n",
    "\n",
    "    # Extract just the time part, post conversion\n",
    "    departures_df['Departure_Time'] = departures_df['Departure_Time'].dt.time\n",
    "    departures_df['Scheduled_Departure_Time'] = departures_df['Scheduled_Departure_Time'].dt.time\n",
    "    \n",
    "    # Append to CSV, checking if the file exists to handle headers\n",
    "    update_or_append_departures(departures_df)\n",
    "    \n",
    "    # Display the updated DataFrame\n",
    "    print(departures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4a8c6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Trip ID: 13678478, Departure Time: 1712022960, Scheduled Departure Time: 1712022960, Is cancelled: False\n",
      "RT Trip ID: 13719923, Departure Time: 1712023680, Scheduled Departure Time: 1712023680, Is cancelled: False\n",
      "RT Trip ID: 13678479, Departure Time: 1712025360, Scheduled Departure Time: 1712025360, Is cancelled: True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gt/psznpdhs4b5c02jv9034ldvc0000gn/T/ipykernel_3524/3529348443.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if __name__ == \"__main__\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/gt/psznpdhs4b5c02jv9034ldvc0000gn/T/ipykernel_3524/4128009100.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdepartures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Departure_Time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepartures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Departure_Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdepartures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scheduled_Departure_Time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdepartures_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scheduled_Departure_Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Append to CSV, checking if the file exists to handle headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mupdate_or_append_departures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepartures_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Display the updated DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepartures_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gt/psznpdhs4b5c02jv9034ldvc0000gn/T/ipykernel_3524/3841219045.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(departures_df, csv_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Update the existing row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mexisting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexisting_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RT_Trip_ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrip_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Append new row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mexisting_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexisting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Write the updated DataFrame back to the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mexisting_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
